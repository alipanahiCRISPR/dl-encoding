{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfTCvHlSanKetzeAQntEXi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alipanahiCRISPR/dl-encoding/blob/master/prime_score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq3WZBywzbOK",
        "outputId": "a8a2380e-da08-4fcc-ea87-081d603bbd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "/bin/bash: line 1: conda: command not found\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Collecting git+https://github.com/Goosang-Yu/genet-models.git\n",
            "  Cloning https://github.com/Goosang-Yu/genet-models.git to /tmp/pip-req-build-tmcawmou\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Goosang-Yu/genet-models.git /tmp/pip-req-build-tmcawmou\n",
            "  Resolved https://github.com/Goosang-Yu/genet-models.git to commit 726ee60e98013cc149c6d52ce8374723171f48dc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting genet\n",
            "  Downloading genet-0.6.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from genet) (1.5.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from genet) (2022.10.31)\n",
            "Collecting biopython (from genet)\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.8.0 (from genet)\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.11.0+cu113 (from genet)\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m498.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.12.0+cu113 (from genet)\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.11.0 (from genet)\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.20.* in /usr/local/lib/python3.10/dist-packages (from genet) (3.20.3)\n",
            "Collecting silence-tensorflow (from genet)\n",
            "  Downloading silence_tensorflow-1.2.1.tar.gz (3.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from genet) (9.0.0)\n",
            "Collecting fastparquet (from genet)\n",
            "  Downloading fastparquet-2023.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (3.8.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0->genet)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0->genet)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0->genet)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0->genet)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (0.32.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->genet) (1.56.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113->genet) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113->genet) (8.4.0)\n",
            "Collecting cramjam>=2.3 (from fastparquet->genet)\n",
            "  Downloading cramjam-2.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet->genet) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet->genet) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->genet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->genet) (2022.7.1)\n",
            "Collecting support_developer (from silence-tensorflow->genet)\n",
            "  Downloading support_developer-1.0.5.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0->genet) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113->genet) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113->genet) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113->genet) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113->genet) (3.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->genet) (3.2.2)\n",
            "Building wheels for collected packages: genet-models, silence-tensorflow, support_developer\n",
            "  Building wheel for genet-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for genet-models: filename=genet_models-1.0.0-py3-none-any.whl size=472867775 sha256=bfbbe249c0e452decf36d3040109d22a0230e66366d141bb22663118f843a0bf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ioj40k8f/wheels/83/27/01/a11e7f5f0200b1bcb21127b6c98bb346ecf074d30fd11502df\n",
            "  Building wheel for silence-tensorflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silence-tensorflow: filename=silence_tensorflow-1.2.1-py3-none-any.whl size=4464 sha256=11d042da0ae4889e0b3b9d211e50d1d99fc77f0618d667091b19d85881550996\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/2c/24/e130d6102c0df56631b9db7479d9a6a53c5d97fb06b5f61b98\n",
            "  Building wheel for support_developer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for support_developer: filename=support_developer-1.0.5-py3-none-any.whl size=5630 sha256=5f886f11a29ef93efb42d9951c2222ce70385d793f4497c2e149ad90856730f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/72/c8/3054a5897ba0713dfa7a941364d68cbd42b0755c8e2ec1c18c\n",
            "Successfully built genet-models silence-tensorflow support_developer\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, support_developer, keras, torch, tensorboard-data-server, silence-tensorflow, keras-preprocessing, genet-models, cramjam, biopython, torchvision, torchaudio, google-auth-oauthlib, fastparquet, tensorboard, tensorflow, genet\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.2+cu118\n",
            "    Uninstalling torchaudio-2.0.2+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.2+cu118\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed biopython-1.81 cramjam-2.6.2 fastparquet-2023.7.0 genet-0.6.0 genet-models-1.0.0 google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 silence-tensorflow-1.2.1 support_developer-1.0.5 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n"
          ]
        }
      ],
      "source": [
        "!conda create -n genet python=3.8\n",
        "!conda activate genet\n",
        "\n",
        "# install genet package in your env.\n",
        "!pip3 install genet -f https://download.pytorch.org/whl/cu113/torch_stable.html git+https://github.com/Goosang-Yu/genet-models.git\n",
        "\n",
        "# install ViennaRNA package for prediction module\n",
        "#!pip install viennarna"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " basic RNA secondary structure analysis software-                               مجموعه‌ای از ابزارها و کتابخانه‌های مستقل برای پیش‌بینی و تحلیل ساختار دوم اسید نوکلئیک است."
      ],
      "metadata": {
        "id": "In2HNtYqMExf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ViennaRNA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSx3Vg_08sZU",
        "outputId": "17700e2f-6a34-4000-93f9-aa2c891ad2b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ViennaRNA\n",
            "  Downloading ViennaRNA-2.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ViennaRNA\n",
            "Successfully installed ViennaRNA-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install biopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x08mrvhbDp9P",
        "outputId": "59a9fc59-d657-4e21-8e30-375290d514db"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopy\n",
            "  Downloading biopy-0.1.2-py3-none-any.whl (70 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopy\n",
            "Successfully installed biopy-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install RNA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY70FXNLLdkR",
        "outputId": "beae307b-d2a2-4868-9249-7a8c4287385d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting RNA\n",
            "  Downloading rna-0.11.0-py3-none-any.whl (66 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from RNA) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from RNA) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->RNA) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->RNA) (1.16.0)\n",
            "Installing collected packages: RNA\n",
            "Successfully installed RNA-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genet import predict as prd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC-CjWZ2Nf5n",
        "outputId": "03779f1a-0971-4794-c2e3-a751e569b1fd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ch7nMbnfQWUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RsDP-5bkLX-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8955345-64c0-491a-f8fa-a1f15a1ba2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 1. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 0.]\n",
            " [0. 1. 1. 0. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0. 1. 0.]\n",
            " [1. 1. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 1. 0. 0. 1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, seq_wt, seq_et, with_category = False, label = None, with_reg_val = False, value = None):\n",
        "        tlen = 24\n",
        "        self.seq_wt = \"-\" *(tlen-len(seq_wt)) +  seq_wt\n",
        "        self.seq_et = \"-\" *(tlen-len(seq_et)) + seq_et\n",
        "        self.encoded_dict_indel = {'A': [1, 0, 0, 0, 0], 'T': [0, 1, 0, 0, 0],\n",
        "                                   'G': [0, 0, 1, 0, 0], 'C': [0, 0, 0, 1, 0], '_': [0, 0, 0, 0, 1], '-': [0, 0, 0, 0, 0]}\n",
        "        self.direction_dict = {'A':5, 'G':4, 'C':3, 'T':2, '_':1}\n",
        "        if with_category:\n",
        "            self.label = label\n",
        "        if with_reg_val:\n",
        "            self.value = value\n",
        "        self.encode_wt_ed()\n",
        "\n",
        "    def encode_seq_wt(self):\n",
        "        code_list = []\n",
        "        encoded_dict = self.encoded_dict_indel\n",
        "        sgRNA_bases = list(self.seq_wt)\n",
        "        for i in range(len(sgRNA_bases)):\n",
        "            if sgRNA_bases[i] == \"N\":\n",
        "                sgRNA_bases[i] = list(self.off_seq)[i]\n",
        "            code_list.append(encoded_dict[sgRNA_bases[i]])\n",
        "        self.sgRNA_code = np.array(code_list)\n",
        "\n",
        "    def encode_seq_et(self):\n",
        "        code_list = []\n",
        "        encoded_dict = self.encoded_dict_indel\n",
        "        off_bases = list(self.seq_et)\n",
        "        for i in range(len(off_bases)):\n",
        "            code_list.append(encoded_dict[off_bases[i]])\n",
        "        self.off_code = np.array(code_list)\n",
        "\n",
        "    def encode_wt_ed(self):\n",
        "        self.encode_seq_wt()\n",
        "        self.encode_seq_et()\n",
        "        on_bases = list(self.seq_wt)\n",
        "        off_bases = list(self.seq_et)\n",
        "        on_off_dim7_codes = []\n",
        "        for i in range(len(on_bases)):\n",
        "            diff_code = np.bitwise_or(self.sgRNA_code[i], self.off_code[i])\n",
        "            on_b = on_bases[i]\n",
        "            off_b = off_bases[i]\n",
        "            if on_b == \"N\":\n",
        "                on_b = off_b\n",
        "\n",
        "            dir_code = np.zeros(2)\n",
        "            if on_b == \"-\" or off_b == \"-\" or self.direction_dict[on_b] == self.direction_dict[off_b]:\n",
        "                pass\n",
        "            else:\n",
        "                if self.direction_dict[on_b] > self.direction_dict[off_b]:\n",
        "                    dir_code[0] = 1\n",
        "                else:\n",
        "                    dir_code[1] = 1\n",
        "            on_off_dim7_codes.append(np.concatenate((diff_code, dir_code)))\n",
        "        self.on_off_code = np.array(on_off_dim7_codes)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "چک اینکدینگ"
      ],
      "metadata": {
        "id": "MOBrF1dOwdFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = Encoder(seq_wt=\"AGCTGATTTTA\", seq_et=\"CG_GTTTTTTG\")\n",
        "print(e.on_off_code)"
      ],
      "metadata": {
        "id": "nN7UHWHfwcAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from genet.utils import *\n",
        "import genet\n",
        "import genet.utils\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import inspect\n",
        "from genet.predict.models import DeepSpCas9, DeepPrime\n",
        "\n",
        "\n",
        "import os, sys, time, regex, logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from glob import glob\n",
        "from Bio.SeqUtils import MeltingTemp as mt\n",
        "from Bio.SeqUtils import gc_fraction as gc\n",
        "from Bio.Seq import Seq\n",
        "from RNA import fold_compound\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "tf.disable_v2_behavior()\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\n",
        "class Deep_xCas9(object):\n",
        "    def __init__(self, filter_size, filter_num, node_1=80, node_2=60, l_rate=0.005):\n",
        "        length = 30\n",
        "        self.inputs = tf.placeholder(tf.float32, [None, 1, length, 4])\n",
        "        self.targets = tf.placeholder(tf.float32, [None, 1])\n",
        "        self.is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "\n",
        "#این لایه ها با توجه به مدل انتخاب شده برای اسکور دهی تعریف می شوند.\"\n",
        "\n",
        "        def create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, name):\n",
        "            # setup the filter input shape for tf.nn.conv_2d\n",
        "            conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,\n",
        "                               num_filters]\n",
        "\n",
        "            # initialise weights and bias for the filter\n",
        "            weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03), name=name + '_W')\n",
        "            bias = tf.Variable(tf.truncated_normal([num_filters]), name=name + '_b')\n",
        "\n",
        "            # setup the convolutional layer operation\n",
        "            out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='VALID')\n",
        "\n",
        "            # add the bias\n",
        "            out_layer += bias\n",
        "\n",
        "            # apply a ReLU non-linear activation\n",
        "            out_layer = tf.layers.dropout(tf.nn.relu(out_layer), 0.3, self.is_training)\n",
        "\n",
        "            # now perform max pooling\n",
        "            ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
        "            strides = [1, 1, 2, 1]\n",
        "            out_layer = tf.nn.avg_pool(out_layer, ksize=ksize, strides=strides, padding='SAME')\n",
        "\n",
        "            return out_layer\n",
        "\n",
        "        # def end: create_new_conv_layer\n",
        "\n",
        "        L_pool_0 = create_new_conv_layer(self.inputs, 4, filter_num[0], [1, filter_size[0]], [1, 2], name='conv1')\n",
        "        L_pool_1 = create_new_conv_layer(self.inputs, 4, filter_num[1], [1, filter_size[1]], [1, 2], name='conv2')\n",
        "        L_pool_2 = create_new_conv_layer(self.inputs, 4, filter_num[2], [1, filter_size[2]], [1, 2], name='conv3')\n",
        "\n",
        "        with tf.variable_scope('Fully_Connected_Layer1'):\n",
        "            layer_node_0 = int((length - filter_size[0]) / 2) + 1\n",
        "            node_num_0   = layer_node_0 * filter_num[0]\n",
        "            layer_node_1 = int((length - filter_size[1]) / 2) + 1\n",
        "            node_num_1   = layer_node_1 * filter_num[1]\n",
        "            layer_node_2 = int((length - filter_size[2]) / 2) + 1\n",
        "            node_num_2   = layer_node_2 * filter_num[2]\n",
        "\n",
        "            L_flatten_0  = tf.reshape(L_pool_0, [-1, node_num_0])\n",
        "            L_flatten_1  = tf.reshape(L_pool_1, [-1, node_num_1])\n",
        "            L_flatten_2  = tf.reshape(L_pool_2, [-1, node_num_2])\n",
        "            L_flatten    = tf.concat([L_flatten_0, L_flatten_1, L_flatten_2], 1, name='concat')\n",
        "\n",
        "            node_num     = node_num_0 + node_num_1 + node_num_2\n",
        "            W_fcl1       = tf.get_variable(\"W_fcl1\", shape=[node_num, node_1])\n",
        "            B_fcl1       = tf.get_variable(\"B_fcl1\", shape=[node_1])\n",
        "            L_fcl1_pre   = tf.nn.bias_add(tf.matmul(L_flatten, W_fcl1), B_fcl1)\n",
        "            L_fcl1       = tf.nn.relu(L_fcl1_pre)\n",
        "            L_fcl1_drop  = tf.layers.dropout(L_fcl1, 0.3, self.is_training)\n",
        "\n",
        "        with tf.variable_scope('Fully_Connected_Layer2'):\n",
        "            W_fcl2       = tf.get_variable(\"W_fcl2\", shape=[node_1, node_2])\n",
        "            B_fcl2       = tf.get_variable(\"B_fcl2\", shape=[node_2])\n",
        "            L_fcl2_pre   = tf.nn.bias_add(tf.matmul(L_fcl1_drop, W_fcl2), B_fcl2)\n",
        "            L_fcl2       = tf.nn.relu(L_fcl2_pre)\n",
        "            L_fcl2_drop  = tf.layers.dropout(L_fcl2, 0.3, self.is_training)\n",
        "\n",
        "        with tf.variable_scope('Output_Layer'):\n",
        "            W_out        = tf.get_variable(\"W_out\", shape=[node_2, 1])\n",
        "            B_out        = tf.get_variable(\"B_out\", shape=[1])\n",
        "            self.outputs = tf.nn.bias_add(tf.matmul(L_fcl2_drop, W_out), B_out)\n",
        "\n",
        "        # Define loss function and optimizer\n",
        "        self.obj_loss    = tf.reduce_mean(tf.square(self.targets - self.outputs))\n",
        "        self.optimizer   = tf.train.AdamOptimizer(l_rate).minimize(self.obj_loss)\n",
        "\n",
        "    # def end: def __init__\n",
        "# class end: Deep_xCas9\n",
        "\n",
        "#این تابع با توجه به مدل از پیش آموزش دیده اسکور همه رشته های طراحی شده را حساب می کند.\"\n",
        "def Model_Finaltest(sess, TEST_X, model):\n",
        "    test_batch = 500\n",
        "    TEST_Z = np.zeros((TEST_X.shape[0], 1), dtype=float)\n",
        "\n",
        "    for i in range(int(np.ceil(float(TEST_X.shape[0]) / float(test_batch)))):\n",
        "        Dict = {model.inputs: TEST_X[i * test_batch:(i + 1) * test_batch], model.is_training: False}\n",
        "        TEST_Z[i * test_batch:(i + 1) * test_batch] = sess.run([model.outputs], feed_dict=Dict)[0]\n",
        "\n",
        "    list_score = sum(TEST_Z.tolist(), [])\n",
        "\n",
        "    return list_score\n",
        "\n",
        "\n",
        "# def end: Model_Finaltest\n",
        "\n",
        "\n",
        "#این تابع برای  اینکدینگ است\"\n",
        "def preprocess_seq(data, seq_length):\n",
        "\n",
        "    seq_onehot = np.zeros((len(data), 1, seq_length, 4), dtype=float)\n",
        "\n",
        "    for l in range(len(data)):\n",
        "        for i in range(seq_length):\n",
        "            try:\n",
        "                data[l][i]\n",
        "            except Exception:\n",
        "                print(data[l], i, seq_length, len(data))\n",
        "\n",
        "            if   data[l][i] in \"Aa\":  seq_onehot[l, 0, i, 0] = 1\n",
        "            elif data[l][i] in \"Cc\":  seq_onehot[l, 0, i, 1] = 1\n",
        "            elif data[l][i] in \"Gg\":  seq_onehot[l, 0, i, 2] = 1\n",
        "            elif data[l][i] in \"Tt\":  seq_onehot[l, 0, i, 3] = 1\n",
        "            elif data[l][i] in \"Xx\":  pass\n",
        "            elif data[l][i] in \"Nn.\": pass\n",
        "            else:\n",
        "                print(\"[Input Error] Non-ATGC character \" + data[l])\n",
        "                sys.exit()\n",
        "\n",
        "    return seq_onehot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\"اسکور دهی بر اساس کریسپر و مدل انتخابی\"\n",
        "def spcas9_score(list_target30:list , gpu_env=0):\n",
        "    '''\n",
        "    input:: list_target  with length 30 n\n",
        "    The list_target30 should have a 30bp sequence in the form of a list.\n",
        "    Also, sequence [24:27] should contain NGG PAM.\n",
        "\n",
        "\n",
        "\n",
        "    list_target30 = [\n",
        "                        'TCACCTTCGTTTTTTTCCTTCTGCAGGAGG',\n",
        "                        'CCTTCGTTTTTTTCCTTCTGCAGGAGGACA',\n",
        "                        'CTTTCAAGAACTCTTCCACCTCCATGGTGT',\n",
        "                        ]\n",
        "\n",
        "    >>> list_out = spcas9_score(list_target30)\n",
        "\n",
        "    >>> out put:: list_out = [2.80322408676147, 2.25273704528808, 53.4233360290527]\n",
        "\n",
        "\n",
        "\n",
        "    out put:: list_out\n",
        "    '''\n",
        "\n",
        "  #  best_model را تغییر دادم در ادامه شاید \"\n",
        "  #در حال حاضر از مدل سایر محققین استفاده می کنم\"\n",
        "\n",
        "  # TensorFlow config\n",
        "    conf = tf.ConfigProto()\n",
        "    conf.gpu_options.allow_growth = True\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % gpu_env\n",
        "\n",
        "    x_test = preprocess_seq(list_target30, 30)\n",
        "\n",
        "    from genet_models import load_deepspcas9\n",
        "\n",
        "    model_dir = load_deepspcas9()\n",
        "\n",
        "    best_model_path = model_dir\n",
        "    best_model = 'PreTrain-Final-3-5-7-100-70-40-0.001-550-80-60'\n",
        "\n",
        "    model_save = '%s/%s' % (best_model_path, best_model)\n",
        "\n",
        "    filter_size = [3, 5, 7]\n",
        "    filter_num  = [100, 70, 40]\n",
        "    args        = [filter_size, filter_num, 0.001, 550]\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    with tf.Session(config=conf) as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        model = Deep_xCas9(filter_size, filter_num, 80, 60, args[2])\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        saver.restore(sess, model_save)\n",
        "\n",
        "        list_score = Model_Finaltest(sess, x_test, model)\n",
        "\n",
        "    return list_score\n",
        "\n",
        "#\"3 تا تابع زیر برای کارهای پرایم ادیتینگ است ولی نمی دانم دقیقا چه می کنند ولی بودنشان برای ساخت تمام رشته های راهنمایی ممکن  ضروری است.\"\n",
        "def reverse_complement(sSeq):\n",
        "    dict_sBases = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N', 'U': 'U', 'n': '',\n",
        "                   '.': '.', '*': '*', 'a': 't', 'c': 'g', 'g': 'c', 't': 'a'}\n",
        "    list_sSeq = list(sSeq)  # Turns the sequence in to a gigantic list\n",
        "    list_sSeq = [dict_sBases[sBase] for sBase in list_sSeq]\n",
        "    return ''.join(list_sSeq)[::-1]\n",
        "\n",
        "# def END: reverse_complement\n",
        "\n",
        "def set_alt_position_window(sStrand, sAltKey, nAltIndex, nIndexStart, nIndexEnd, nAltLen):\n",
        "    if sStrand == '+':\n",
        "\n",
        "        if sAltKey.startswith('sub'):\n",
        "            return (nAltIndex + 1) - (nIndexStart - 3)\n",
        "        else:\n",
        "            return (nAltIndex + 1) - (nIndexStart - 3)\n",
        "\n",
        "    else:\n",
        "        if sAltKey.startswith('sub'):\n",
        "            return nIndexEnd - nAltIndex + 3 - (nAltLen - 1)\n",
        "\n",
        "        elif sAltKey.startswith('del'):\n",
        "            return nIndexEnd - nAltIndex + 3 - nAltLen\n",
        "\n",
        "        else:\n",
        "            return nIndexEnd - nAltIndex + 3 + nAltLen\n",
        "        # if END:\n",
        "    # if END:\n",
        "\n",
        "# def END: set_alt_position_window\n",
        "\n",
        "\n",
        "def set_PAM_nicking_pos(sStrand, sAltType, nAltLen, nAltIndex, nIndexStart, nIndexEnd):\n",
        "    if sStrand == '-':\n",
        "        nPAM_Nick = nIndexEnd + 3\n",
        "    else:\n",
        "        nPAM_Nick = nIndexStart - 3\n",
        "\n",
        "    return nPAM_Nick\n",
        "\n",
        "# def END: set_PAM_Nicking_Pos\n",
        "\n",
        "\n",
        "def check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, sAltType, nAltLen, nAltIndex):\n",
        "    nUp, nDown = dict_sWinSize[sAltType][nAltLen]\n",
        "\n",
        "    if sStrand == '+':\n",
        "        nPAMCheck_min = nAltIndex - nUp + 1\n",
        "        nPAMCheck_max = nAltIndex + nDown + 1\n",
        "    else:\n",
        "        nPAMCheck_min = nAltIndex - nDown + 1\n",
        "        nPAMCheck_max = nAltIndex + nUp + 1\n",
        "    # if END:\n",
        "\n",
        "    if nIndexStart < nPAMCheck_min or nIndexEnd > nPAMCheck_max:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# def END: check_PAM_window\n",
        "\n",
        "\n",
        "\n",
        "#ویژگی های دخیل در دقت ویرایش پرایم ادیتینگ استخراج و  بر اساس آنها اسکور نهایی پرایم ادیتینگ حساب می شود.\"\n",
        "class FeatureExtraction:\n",
        "    def __init__(self):\n",
        "        self.sGuideKey = ''\n",
        "        self.sChrID = ''\n",
        "        self.sStrand = ''\n",
        "        self.nGenomicPos = 0\n",
        "        self.nEditIndex = 0\n",
        "        self.nPBSLen = 0\n",
        "        self.nRTTLen = 0\n",
        "        self.sPBSSeq = ''\n",
        "        self.sRTSeq = ''\n",
        "        self.sPegRNASeq = ''\n",
        "        self.sWTSeq = ''\n",
        "        self.sEditedSeq = ''\n",
        "        self.list_sSeqs = []\n",
        "        self.type_sub = 0\n",
        "        self.type_ins = 0\n",
        "        self.type_del = 0\n",
        "        self.fTm1 = 0.0\n",
        "        self.fTm2 = 0.0\n",
        "        self.fTm2new = 0.0\n",
        "        self.fTm3 = 0.0\n",
        "        self.fTm4 = 0.0\n",
        "        self.fTmD = 0.0\n",
        "        self.fMFE3 = 0.0\n",
        "        self.fMFE4 = 0.0\n",
        "        self.nGCcnt1 = 0\n",
        "        self.nGCcnt2 = 0\n",
        "        self.nGCcnt3 = 0\n",
        "        self.fGCcont1 = 0.0\n",
        "        self.fGCcont2 = 0.0\n",
        "        self.fGCcont3 = 0.0\n",
        "        self.dict_sSeqs = {}\n",
        "        self.dict_sCombos = {}\n",
        "        self.dict_sOutput = {}\n",
        "\n",
        "    # def End: __init__\n",
        "\n",
        "\n",
        "\n",
        "  #\"   با توجه به ورودی که از کاربر می گیریم متغییر ها مقدار دهی می شود  من فعلا 3 متغییر را می گیرم \"\n",
        "  #\"بعد تعریف پوسته برنامه این قسمت تغییر خواهد کرد.\"\n",
        "    def get_input(self, wt_seq, ed_seq, edit_type, edit_len):\n",
        "        self.sWTSeq = wt_seq.upper()\n",
        "        self.sEditedSeq = ed_seq.upper()\n",
        "        self.sAltKey = edit_type + str(edit_len)\n",
        "        self.sAltType = edit_type\n",
        "        self.nAltLen = edit_len\n",
        "\n",
        "        if   self.sAltType.startswith('sub'): self.type_sub = 1\n",
        "        elif self.sAltType.startswith('del'): self.type_del = 1\n",
        "        elif self.sAltType.startswith('ins'): self.type_ins = 1\n",
        "\n",
        "    # def End: get_input\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   #\"بعد گرفتن پارامترها از کاربر تمام رشته های راهنمای ممکن باید طراحی و سپس اسکور دهی شوند.\"\n",
        "   #\"برای ساخت تمام رشته های ممکن از کد های گیتاپ استفاده کرده ام.\"\n",
        "\n",
        "   #\" RT_PBS اول تمام \"\n",
        "   #\"pegRNA بعد تمام \"\n",
        "\n",
        "    def get_sAltNotation(self, nAltIndex):\n",
        "        if self.sAltType == 'sub':\n",
        "            self.sAltNotation = '%s>%s' % (\n",
        "                self.sWTSeq[nAltIndex:nAltIndex + self.nAltLen], self.sEditedSeq[nAltIndex:nAltIndex + self.nAltLen])\n",
        "\n",
        "        elif self.sAltType == 'del':\n",
        "            self.sAltNotation = '%s>%s' % (\n",
        "                self.sWTSeq[nAltIndex:nAltIndex + 1 + self.nAltLen], self.sEditedSeq[nAltIndex])\n",
        "\n",
        "        else:\n",
        "            self.sAltNotation = '%s>%s' % (\n",
        "                self.sWTSeq[nAltIndex], self.sEditedSeq[nAltIndex:nAltIndex + self.nAltLen + 1])\n",
        "\n",
        "    # def END: get_sAltNotation\n",
        "\n",
        "    def get_all_RT_PBS(self,\n",
        "                    nAltIndex,\n",
        "                    nMinPBS = 0,\n",
        "                    nMaxPBS = 17,\n",
        "                    nMaxRT = 40,\n",
        "                    nSetPBSLen = 0,\n",
        "                    nSetRTLen = 0,\n",
        "                    pe_system = 'PE2'\n",
        "                    ):\n",
        "        \"\"\"\n",
        "        nMinPBS: If you set specific number, lower than MinPBS will be not generated. Default=0\n",
        "        nMaxPBS: If you set specific number, higher than MinPBS will be not generated. Default=17\n",
        "        nMaxRT = : If you set specific number, higher than MinPBS will be not generated. Default=40\n",
        "        nSetPBSLen = 0  # Fix PBS Len: Set if >0\n",
        "        nSetRTLen = 0  # Fix RT  Len: Set if >0\n",
        "        PAM: 4-nt sequence\n",
        "        \"\"\"\n",
        "\n",
        "        nMaxEditPosWin = nMaxRT + 3  # Distance between PAM and mutation\n",
        "\n",
        "        dict_sWinSize = {'sub': {1: [nMaxRT - 1 - 3, 6], 2: [nMaxRT - 2 - 3, 6], 3: [nMaxRT - 3 - 3, 6]},\n",
        "                        'ins': {1: [nMaxRT - 2 - 3, 6], 2: [nMaxRT - 3 - 3, 6], 3: [nMaxRT - 4 - 3, 6]},\n",
        "                        'del': {1: [nMaxRT - 1 - 3, 6], 2: [nMaxRT - 1 - 3, 6], 3: [nMaxRT - 1 - 3, 6]}}\n",
        "\n",
        "\n",
        "        if 'NRCH' in pe_system: # for NRCH-PE PAM\n",
        "            dict_sRE = {'+': '[ACGT][ACGT]G[ACGT]|[ACGT][CG]A[ACGT]|[ACGT][AG]CC|[ATCG]ATG',\n",
        "                        '-': '[ACGT]C[ACGT][ACGT]|[ACGT]T[CG][ACGT]|G[GT]T[ACGT]|ATT[ACGT]|CAT[ACGT]|GGC[ACGT]|GTA[ACGT]'}\n",
        "        else:\n",
        "            dict_sRE = {'+': '[ACGT]GG[ACGT]', '-': '[ACGT]CC[ACGT]'} # for Original-PE PAM\n",
        "\n",
        "        for sStrand in ['+', '-']:\n",
        "\n",
        "            sRE = dict_sRE[sStrand]\n",
        "            for sReIndex in regex.finditer(sRE, self.sWTSeq, overlapped=True):\n",
        "\n",
        "                if sStrand == '+':\n",
        "                    nIndexStart = sReIndex.start()\n",
        "                    nIndexEnd = sReIndex.end() - 1\n",
        "                    sPAMSeq = self.sWTSeq[nIndexStart:nIndexEnd]\n",
        "                    sGuideSeq = self.sWTSeq[nIndexStart - 20:nIndexEnd]\n",
        "                else:\n",
        "                    nIndexStart = sReIndex.start() + 1\n",
        "                    nIndexEnd = sReIndex.end()\n",
        "                    sPAMSeq = reverse_complement(self.sWTSeq[nIndexStart:nIndexEnd])\n",
        "                    sGuideSeq = reverse_complement(self.sWTSeq[nIndexStart:nIndexEnd + 20])\n",
        "\n",
        "                nAltPosWin = set_alt_position_window(sStrand, self.sAltKey, nAltIndex, nIndexStart, nIndexEnd,\n",
        "                                                    self.nAltLen)\n",
        "\n",
        "                ## AltPosWin Filter ##\n",
        "                if nAltPosWin <= 0:             continue\n",
        "                if nAltPosWin > nMaxEditPosWin: continue\n",
        "\n",
        "                nPAM_Nick = set_PAM_nicking_pos(sStrand, self.sAltType, self.nAltLen, nAltIndex, nIndexStart, nIndexEnd)\n",
        "\n",
        "                if not check_PAM_window(dict_sWinSize, sStrand, nIndexStart, nIndexEnd, self.sAltType, self.nAltLen,\n",
        "                                        nAltIndex): continue\n",
        "\n",
        "                sPAMKey = '%s,%s,%s,%s,%s,%s,%s' % (\n",
        "                    self.sAltKey, self.sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq)\n",
        "\n",
        "                dict_sRT, dict_sPBS = self.determine_PBS_RT_seq(sStrand, nMinPBS, nMaxPBS, nMaxRT, nSetPBSLen,\n",
        "                                                        nSetRTLen, nAltIndex, nPAM_Nick, nAltPosWin, self.sEditedSeq)\n",
        "\n",
        "                nCnt1, nCnt2 = len(dict_sRT), len(dict_sPBS)\n",
        "                if nCnt1 == 0: continue\n",
        "                if nCnt2 == 0: continue\n",
        "\n",
        "                if sPAMKey not in self.dict_sSeqs:\n",
        "                    self.dict_sSeqs[sPAMKey] = ''\n",
        "                self.dict_sSeqs[sPAMKey] = [dict_sRT, dict_sPBS]\n",
        "\n",
        "            # loop END: sReIndex\n",
        "        # loop END: sStrand\n",
        "\n",
        "\n",
        "    # def END: get_all_RT_PBS\n",
        "\n",
        "\n",
        "    def determine_PBS_RT_seq(self, sStrand, nMinPBS, nMaxPBS, nMaxRT, nSetPBSLen, nSetRTLen, nAltIndex, nPAM_Nick,\n",
        "                            nAltPosWin, sForTempSeq):\n",
        "        dict_sPBS = {}\n",
        "        dict_sRT = {}\n",
        "\n",
        "        list_nPBSLen = [nNo + 1 for nNo in range(nMinPBS, nMaxPBS)]\n",
        "        for nPBSLen in list_nPBSLen:\n",
        "\n",
        "            ## Set PBS Length ##\n",
        "            if nSetPBSLen:\n",
        "                if nPBSLen != nSetPBSLen: continue\n",
        "\n",
        "            if sStrand == '+':\n",
        "                nPBSStart = nPAM_Nick - nPBSLen  # 5' -> PamNick\n",
        "                nPBSEnd = nPAM_Nick\n",
        "                sPBSSeq = sForTempSeq[nPBSStart:nPBSEnd] # sForTempSeq = self.EditedSeq\n",
        "\n",
        "            else:\n",
        "                if self.sAltKey.startswith('sub'):\n",
        "                    nPBSStart = nPAM_Nick\n",
        "                elif self.sAltKey.startswith('ins'):\n",
        "                    nPBSStart = nPAM_Nick + self.nAltLen\n",
        "                elif self.sAltKey.startswith('del'):\n",
        "                    nPBSStart = nPAM_Nick - self.nAltLen\n",
        "\n",
        "                sPBSSeq = reverse_complement(sForTempSeq[nPBSStart:nPBSStart + nPBSLen]) # sForTempSeq = self.EditedSeq\n",
        "\n",
        "            # if END: sStrand\n",
        "\n",
        "            sKey = len(sPBSSeq)\n",
        "            if sKey not in dict_sPBS:\n",
        "                dict_sPBS[sKey] = ''\n",
        "            dict_sPBS[sKey] = sPBSSeq\n",
        "        # loop END: nPBSLen\n",
        "\n",
        "        if sStrand == '+':\n",
        "            if self.sAltKey.startswith('sub'):\n",
        "                list_nRTPos = [nNo + 1 for nNo in range(nAltIndex + self.nAltLen, (nPAM_Nick + nMaxRT))] # OK\n",
        "            elif self.sAltKey.startswith('ins'):\n",
        "                list_nRTPos = [nNo + 1 for nNo in range(nAltIndex + self.nAltLen, (nPAM_Nick + nMaxRT))] # OK\n",
        "            else:\n",
        "                list_nRTPos = [nNo + 1 for nNo in range(nAltIndex, (nPAM_Nick + nMaxRT))] ## 수정! ## del2 RHA 3 del1 RHA2\n",
        "        else:\n",
        "            if self.sAltKey.startswith('sub'):\n",
        "                list_nRTPos = [nNo for nNo in range(nPAM_Nick - 1 - nMaxRT, nAltIndex)] ## 수정! ## sub1 sub 3 RHA 0\n",
        "            else:\n",
        "                list_nRTPos = [nNo for nNo in range(nPAM_Nick - 3 - nMaxRT, nAltIndex + self.nAltLen - 1)] ## 수정! ## ins2 최소가 2까지 ins3 RHA 최소 3 #del2 RHA 2 del1 RHA1\n",
        "        for nRTPos in list_nRTPos:\n",
        "\n",
        "            if sStrand == '+':\n",
        "                nRTStart = nPAM_Nick  # PamNick -> 3'\n",
        "                nRTEnd = nRTPos\n",
        "                sRTSeq = sForTempSeq[nRTStart:nRTEnd]\n",
        "\n",
        "            else:\n",
        "                if self.sAltKey.startswith('sub'):\n",
        "                    nRTStart = nRTPos\n",
        "                    nRTEnd = nPAM_Nick  # PamNick -> 3'\n",
        "                elif self.sAltKey.startswith('ins'):\n",
        "                    nRTStart = nRTPos\n",
        "                    nRTEnd = nPAM_Nick + self.nAltLen  # PamNick -> 3'\n",
        "                elif self.sAltKey.startswith('del'):\n",
        "                    nRTStart = nRTPos\n",
        "                    nRTEnd = nPAM_Nick - self.nAltLen  # PamNick -> 3'\n",
        "\n",
        "                sRTSeq = reverse_complement(sForTempSeq[nRTStart:nRTEnd])\n",
        "\n",
        "                if not sRTSeq: continue\n",
        "            # if END: sStrand\n",
        "\n",
        "            sKey = len(sRTSeq)\n",
        "\n",
        "            ## Set RT Length ##\n",
        "            if nSetRTLen:\n",
        "                if sKey != nSetRTLen: continue\n",
        "\n",
        "            ## Limit Max RT len ##\n",
        "            if sKey > nMaxRT: continue\n",
        "\n",
        "            ## min RT from nick site to mutation ##\n",
        "            if self.sAltKey.startswith('sub'):\n",
        "                if sStrand == '+':\n",
        "                    if sKey < abs(nAltIndex - nPAM_Nick): continue\n",
        "                else:\n",
        "                    if sKey < abs(nAltIndex - nPAM_Nick + self.nAltLen - 1): continue ###\n",
        "            else:\n",
        "                if sStrand == '-':\n",
        "                    if sKey < abs(nAltIndex - nPAM_Nick + self.nAltLen - 1): continue\n",
        "\n",
        "            if self.sAltKey.startswith('ins'):\n",
        "                if sKey < nAltPosWin + 1: continue\n",
        "\n",
        "            if sKey not in dict_sRT:\n",
        "                dict_sRT[sKey] = ''\n",
        "            dict_sRT[sKey] = sRTSeq\n",
        "        # loop END: nRTPos\n",
        "\n",
        "        return [dict_sRT, dict_sPBS]\n",
        "\n",
        "\n",
        "    # def END: determine_PBS_RT_seq\n",
        "\n",
        "    def make_rt_pbs_combinations(self):\n",
        "        for sPAMKey in self.dict_sSeqs:\n",
        "\n",
        "            dict_sRT, dict_sPBS = self.dict_sSeqs[sPAMKey]\n",
        "\n",
        "            list_sRT = [dict_sRT[sKey] for sKey in dict_sRT]\n",
        "            list_sPBS = [dict_sPBS[sKey] for sKey in dict_sPBS]\n",
        "\n",
        "            if sPAMKey not in self.dict_sCombos:\n",
        "                self.dict_sCombos[sPAMKey] = ''\n",
        "            self.dict_sCombos[sPAMKey] = {'%s,%s' % (sRT, sPBS): {} for sRT in list_sRT for sPBS in list_sPBS}\n",
        "        # loop END: sPAMKey\n",
        "\n",
        "\n",
        "    # def END: make_rt_pbs_combinations\n",
        "\n",
        "\n",
        "    def determine_seqs(self):\n",
        "        for sPAMKey in self.dict_sSeqs:\n",
        "\n",
        "            sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')\n",
        "            nAltPosWin = int(nAltPosWin)\n",
        "            nNickIndex = int(nPAM_Nick)\n",
        "\n",
        "            # if sStrand == '+':\n",
        "            #     sWTSeq74 = self.sWTSeq[nNickIndex - 21:nNickIndex + 53]\n",
        "            # else:\n",
        "            #     sWTSeq74 = reverse_complement(self.sWTSeq[nNickIndex - 53:nNickIndex + 21])\n",
        "\n",
        "            for sSeqKey in self.dict_sCombos[sPAMKey]:\n",
        "\n",
        "                sRTSeq, sPBSSeq = sSeqKey.split(',')\n",
        "\n",
        "                ## for Tm1\n",
        "                sForTm1 = reverse_complement(sPBSSeq.replace('A', 'U'))\n",
        "\n",
        "                if sStrand == '+':\n",
        "                    ## for Tm2\n",
        "                    sForTm2 = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq)]\n",
        "\n",
        "                    ## for Tm2new\n",
        "                    if self.sAltType.startswith('sub'):\n",
        "                        sForTm2new = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq)]\n",
        "                    elif self.sAltType.startswith('ins'):\n",
        "                        sForTm2new = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) - self.nAltLen]\n",
        "                    else:  # del\n",
        "                        sForTm2new = self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) + self.nAltLen]\n",
        "\n",
        "                    ## for Tm3\n",
        "                    if self.sAltType.startswith('sub'):\n",
        "                        sTm3antiSeq = reverse_complement(self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq)])\n",
        "                    elif self.sAltType.startswith('ins'):\n",
        "                        sTm3antiSeq = reverse_complement(self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) - self.nAltLen])\n",
        "                    else:  # del\n",
        "                        sTm3antiSeq = reverse_complement(self.sWTSeq[nNickIndex:nNickIndex + len(sRTSeq) + self.nAltLen])\n",
        "\n",
        "                else:\n",
        "                    ## for Tm2\n",
        "                    sForTm2 = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq):nNickIndex])\n",
        "\n",
        "                    ## for Tm2new\n",
        "                    if self.sAltType.startswith('sub'):\n",
        "                        sForTm2new = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq):nNickIndex])\n",
        "                    elif self.sAltType.startswith('ins'):\n",
        "                        sForTm2new = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq) + self.nAltLen:nNickIndex])\n",
        "                    else:  # del\n",
        "                        sForTm2new = reverse_complement(self.sWTSeq[nNickIndex - len(sRTSeq) - self.nAltLen:nNickIndex])\n",
        "\n",
        "                    ## for Tm3\n",
        "                    if self.sAltType.startswith('sub'):\n",
        "                        sTm3antiSeq = self.sWTSeq[nNickIndex - len(sRTSeq):nNickIndex]\n",
        "                    elif self.sAltType.startswith('ins'):\n",
        "                        sTm3antiSeq = self.sWTSeq[nNickIndex - len(sRTSeq) + self.nAltLen:nNickIndex]\n",
        "                    else:  # del\n",
        "                        sTm3antiSeq = self.sWTSeq[nNickIndex - len(sRTSeq) - self.nAltLen:nNickIndex]\n",
        "\n",
        "                # if END\n",
        "\n",
        "                sForTm3 = [sRTSeq, sTm3antiSeq]\n",
        "\n",
        "                ## for Tm4\n",
        "                sForTm4 = [reverse_complement(sRTSeq.replace('A', 'U')), sRTSeq]\n",
        "\n",
        "\n",
        "                self.dict_sCombos[sPAMKey][sSeqKey] = {'Tm1': sForTm1,\n",
        "                                                        'Tm2': sForTm2,\n",
        "                                                        'Tm2new': sForTm2new,\n",
        "                                                        'Tm3': sForTm3,\n",
        "                                                        'Tm4': sForTm4}\n",
        "            # loop END: sSeqKey\n",
        "        # loop END: sPAMKey\n",
        "    # def END: determine_seqs\n",
        "\n",
        "\n",
        "#\" تا اینجا تمام رشته های  PegRNA را تعریف کردم\"\n",
        "\n",
        "\n",
        "#  \"حال ساختار دوم رشته ها \"\n",
        "#   \"برای اسکور دهی کلا 3 نوع پارامتر در نظر گرفته می شود ویژگی های رشته های ورودی ، ساختار دوم و اینتراکشن ژن ها\"\n",
        "#\"تا اینجا داشتیم  پارامترهای تاثیر گذار  را از ساختار رشته های ورودی استخراج می کردیم\n",
        "#\" در ادامه ویژگی های مربوط به ساختار دوم ژن بررسی می شود.\"\n",
        "\n",
        "    def determine_secondary_structure(self):\n",
        "        for sPAMKey in self.dict_sSeqs:\n",
        "\n",
        "            sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')\n",
        "            list_sOutputKeys = ['Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD', 'nGCcnt1', 'nGCcnt2', 'nGCcnt3',\n",
        "                        'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4']\n",
        "\n",
        "            if sPAMKey not in self.dict_sOutput:\n",
        "                self.dict_sOutput[sPAMKey] = {}\n",
        "\n",
        "            for sSeqKey in self.dict_sCombos[sPAMKey]:\n",
        "\n",
        "                if sSeqKey not in self.dict_sOutput[sPAMKey]:\n",
        "\n",
        "                    self.dict_sOutput[sPAMKey][sSeqKey] = {sKey: '' for sKey in list_sOutputKeys}\n",
        "\n",
        "                self.determine_Tm(sPAMKey, sSeqKey)\n",
        "                self.determine_GC(sPAMKey, sSeqKey)\n",
        "                self.determine_MFE(sPAMKey, sSeqKey, sGuideSeq)\n",
        "            # loop END: sSeqKey\n",
        "        # loop END: sPAMKey\n",
        "\n",
        "\n",
        "\n",
        "#\"بررسی اینتراکشن ها \"\n",
        "    def determine_Tm(self, sPAMKey, sSeqKey):\n",
        "        sForTm1 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm1']\n",
        "        sForTm2 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm2']\n",
        "        sForTm2new = self.dict_sCombos[sPAMKey][sSeqKey]['Tm2new']\n",
        "        sForTm3 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm3']\n",
        "        sForTm4 = self.dict_sCombos[sPAMKey][sSeqKey]['Tm4']\n",
        "\n",
        "        ## Tm1 DNA/RNA mm1 ##\n",
        "        fTm1 = mt.Tm_NN(seq=Seq(sForTm1), nn_table=mt.R_DNA_NN1)\n",
        "\n",
        "        ## Tm2 DNA/DNA mm0 ##\n",
        "        fTm2 = mt.Tm_NN(seq=Seq(sForTm2), nn_table=mt.DNA_NN3)\n",
        "\n",
        "        ## Tm2new DNA/DNA mm0 ##\n",
        "        fTm2new = mt.Tm_NN(seq=Seq(sForTm2new), nn_table=mt.DNA_NN3)\n",
        "\n",
        "        ## Tm3 DNA/DNA mm1 ##\n",
        "        if not sForTm3:\n",
        "            fTm3 = 0\n",
        "            fTm5 = 0\n",
        "\n",
        "        else:\n",
        "            list_fTm3 = []\n",
        "            for sSeq1, sSeq2 in zip(sForTm3[0], sForTm3[1]):\n",
        "                try:\n",
        "                    fTm3 = mt.Tm_NN(seq=sSeq1, c_seq=sSeq2, nn_table=mt.DNA_NN3)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "                list_fTm3.append(fTm3)\n",
        "            # loop END: sSeq1, sSeq2\n",
        "\n",
        "        # if END:\n",
        "\n",
        "        # Tm4 - revcom(AAGTcGATCC(RNA version)) + AAGTcGATCC\n",
        "        fTm4 = mt.Tm_NN(seq=Seq(sForTm4[0]), nn_table=mt.R_DNA_NN1)\n",
        "\n",
        "        # Tm5 - Tm3 - Tm2\n",
        "        fTm5 = fTm3 - fTm2\n",
        "\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['Tm1'] = fTm1\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['Tm2'] = fTm2\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['Tm2new'] = fTm2new\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['Tm3'] = fTm3\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['Tm4'] = fTm4\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['TmD'] = fTm5\n",
        "\n",
        "    # def END: determine_Tm\n",
        "\n",
        "\n",
        "    def determine_GC(self, sPAMKey, sSeqKey):\n",
        "        sRTSeqAlt, sPBSSeq = sSeqKey.split(',')\n",
        "\n",
        "        self.nGCcnt1 = sPBSSeq.count('G') + sPBSSeq.count('C')\n",
        "        self.nGCcnt2 = sRTSeqAlt.count('G') + sRTSeqAlt.count('C')\n",
        "        self.nGCcnt3 = (sPBSSeq + sRTSeqAlt).count('G') + (sPBSSeq + sRTSeqAlt).count('C')\n",
        "        self.fGCcont1 = 100 * gc(sPBSSeq)\n",
        "        self.fGCcont2 = 100 * gc(sRTSeqAlt)\n",
        "        self.fGCcont3 = 100 * gc(sPBSSeq + sRTSeqAlt)\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['nGCcnt1'] = self.nGCcnt1\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['nGCcnt2'] = self.nGCcnt2\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['nGCcnt3'] = self.nGCcnt3\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['fGCcont1'] = self.fGCcont1\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['fGCcont2'] = self.fGCcont2\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['fGCcont3'] = self.fGCcont3\n",
        "\n",
        "\n",
        "    # def END: determine_GC\n",
        "\n",
        "    def determine_MFE(self, sPAMKey, sSeqKey, sGuideSeqExt):\n",
        "\n",
        "        sRTSeq, sPBSSeq = sSeqKey.split(',')\n",
        "\n",
        "        ## Set GuideRNA seq ##\n",
        "        sGuideSeq = 'G' + sGuideSeqExt[1:-3] ## GN19 guide seq\n",
        "\n",
        "        # MFE_3 - RT + PBS + PolyT\n",
        "        sInputSeq = reverse_complement(sPBSSeq + sRTSeq) + 'TTTTTT'\n",
        "        sDBSeq, fMFE3 = fold_compound(sInputSeq).mfe()\n",
        "\n",
        "        # MFE_4 - spacer only\n",
        "        sInputSeq = sGuideSeq\n",
        "        sDBSeq, fMFE4 = fold_compound(sInputSeq).mfe()\n",
        "\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['MFE3'] = round(fMFE3, 1)\n",
        "        self.dict_sOutput[sPAMKey][sSeqKey]['MFE4'] = round(fMFE4, 1)\n",
        "\n",
        "    # def END: determine_MFE\n",
        "\n",
        "\n",
        "\n",
        "#\"این تابع برای مشخص  کردن ستون هایی است که در خروجی نمایش داده می شود.\"\n",
        "#\" هر یک از این پارامترها را در بالا تعریف و حساب کرده ایم و حال نمایش می دهیم.\"\n",
        "\n",
        "#\"برای همه  رشته ها که اسکور آنها را حساب کردم این خروجی ها حساب می شود ولی من فقط 10 تا را نمایش می دهم.\"\n",
        "\n",
        "\n",
        "    def make_output_df(self):\n",
        "\n",
        "        list_output = []\n",
        "        list_sOutputKeys = ['Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD', 'nGCcnt1', 'nGCcnt2', 'nGCcnt3',\n",
        "                        'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4']\n",
        "\n",
        "        for sPAMKey in self.dict_sSeqs:\n",
        "\n",
        "            sAltKey, sAltNotation, sStrand, nPAM_Nick, nAltPosWin, sPAMSeq, sGuideSeq = sPAMKey.split(',')\n",
        "            nNickIndex = int(nPAM_Nick)\n",
        "\n",
        "            if sStrand == '+':\n",
        "                sWTSeq74 = self.sWTSeq[nNickIndex - 21:nNickIndex + 53]\n",
        "                nEditPos = 61 - nNickIndex\n",
        "            else:\n",
        "                sWTSeq74 = reverse_complement(self.sWTSeq[nNickIndex - 53:nNickIndex + 21])\n",
        "                if not self.sAltType.startswith('ins'):\n",
        "                    nEditPos = nNickIndex - 60 - self.nAltLen + 1\n",
        "                else:\n",
        "                    nEditPos = nNickIndex - 59\n",
        "\n",
        "            for sSeqKey in self.dict_sOutput[sPAMKey]:\n",
        "\n",
        "                dict_seq = self.dict_sCombos[sPAMKey][sSeqKey]\n",
        "                sRTTSeq, sPBSSeq = sSeqKey.split(',')\n",
        "                PBSlen = len(sPBSSeq)\n",
        "                RTlen = len(sRTTSeq)\n",
        "\n",
        "                sPBS_RTSeq = sPBSSeq + sRTTSeq\n",
        "                s5Bufferlen = 21 - PBSlen\n",
        "                s3Bufferlen = 53 - RTlen\n",
        "                sEDSeq74 = 'x' * s5Bufferlen + sPBS_RTSeq + 'x' * s3Bufferlen\n",
        "\n",
        "                if self.sAltType.startswith('del'):\n",
        "                    RHA_len = len(sRTTSeq) - nEditPos + 1\n",
        "                else:\n",
        "                    RHA_len = len(sRTTSeq) - nEditPos - self.nAltLen + 1\n",
        "\n",
        "\n",
        "                list_sOut = [self.input_id, sWTSeq74, sEDSeq74,\n",
        "                            len(sPBSSeq), len(sRTTSeq), len(sPBSSeq + sRTTSeq), nEditPos, self.nAltLen,\n",
        "                            RHA_len, self.type_sub, self.type_ins, self.type_del\n",
        "                            ] + [self.dict_sOutput[sPAMKey][sSeqKey][sKey] for sKey in list_sOutputKeys]\n",
        "\n",
        "                list_output.append(list_sOut)\n",
        "\n",
        "            # loop END: sSeqKey\n",
        "\n",
        "        hder_essen = ['ID', 'WT74_On', 'Edited74_On', 'PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len',\n",
        "                    'type_sub', 'type_ins', 'type_del','Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n",
        "                    'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4']\n",
        "\n",
        "        df_out = pd.DataFrame(list_output, columns=hder_essen)\n",
        "\n",
        "        # loop END: sPAMKey\n",
        "\n",
        "        return df_out\n",
        "\n",
        "# def END: make_output\n",
        "\n",
        "#\"برای اسکور دهی کلا 3 نوع پارامتر در نظر گرفته می شود ویژگی های رشته های ورودی ، ساختار دوم و اینتراکشن ژن ها\"\n",
        "#\"تا اینجا داشتیم  پارامترهای تاثیر گذار  را از ساختار رشته های ورودی استخراج و ساختار دوم می کردیم\n",
        "#\" در ادامه ویژگی های مربوط به اینتراکشن ژن ها بررسی می شود.\"\n",
        "\n",
        "\n",
        "\n",
        "class GeneInteractionModel(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, hidden_size, num_layers, num_features=24, dropout=0.1):\n",
        "        super(GeneInteractionModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.c1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4, out_channels=128, kernel_size=(2, 3), stride=1, padding=(0, 1)),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.c2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=128, out_channels=108, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(108),\n",
        "            nn.GELU(),\n",
        "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv1d(in_channels=108, out_channels=108, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(108),\n",
        "            nn.GELU(),\n",
        "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv1d(in_channels=108, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.GELU(),\n",
        "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.r = nn.GRU(128, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.s = nn.Linear(2 * hidden_size, 12, bias=False)\n",
        "\n",
        "        self.d = nn.Sequential(\n",
        "            nn.Linear(num_features, 96, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(96, 64, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 128, bias=False)\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.BatchNorm1d(140),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(140, 1, bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g = torch.squeeze(self.c1(g), 2)\n",
        "        g = self.c2(g)\n",
        "        g, _ = self.r(torch.transpose(g, 1, 2))\n",
        "        g = self.s(g[:, -1, :])\n",
        "\n",
        "        x = self.d(x)\n",
        "\n",
        "        out = self.head(torch.cat((g, x), dim=1))\n",
        "\n",
        "        return F.softplus(out)\n",
        "\n",
        "def seq_concat(data, col1='WT74_On', col2='Edited74_On', seq_length=74):\n",
        "    wt = preprocess_seq(data[col1], seq_length)\n",
        "    ed = preprocess_seq(data[col2], seq_length)\n",
        "    g = np.concatenate((wt, ed), axis=1)\n",
        "    g = 2 * g - 1\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "def select_cols(data):\n",
        "    features = data.loc[:, ['PBSlen', 'RTlen', 'RT-PBSlen', 'Edit_pos', 'Edit_len', 'RHA_len', 'type_sub',\n",
        "                            'type_ins', 'type_del', 'Tm1', 'Tm2', 'Tm2new', 'Tm3', 'Tm4', 'TmD',\n",
        "                            'nGCcnt1', 'nGCcnt2', 'nGCcnt3', 'fGCcont1', 'fGCcont2', 'fGCcont3', 'MFE3', 'MFE4', 'DeepSpCas9_score']]\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "def calculate_deepprime_score(df_input, pe_system='PE2max', cell_type='HEK293T'):\n",
        "\n",
        "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#در ادامه کار با مدل برت من جایگزین می شود.\n",
        "    from genet_models import load_deepprime\n",
        "\n",
        "    model_dir, model_type = load_deepprime(pe_system, cell_type)\n",
        "\n",
        "    mean = pd.read_csv('%s/DeepPrime_base/mean.csv' % model_dir, header=None, index_col=0).squeeze()\n",
        "    std  = pd.read_csv('%s/DeepPrime_base/std.csv' % model_dir, header=None, index_col=0).squeeze()\n",
        "\n",
        "    test_features = select_cols(df_input)\n",
        "\n",
        "    g_test = seq_concat(df_input)\n",
        "    x_test = (test_features - mean) / std\n",
        "\n",
        "    g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n",
        "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)\n",
        "\n",
        "    models = [m_files for m_files in glob('%s/%s/*.pt' % (model_dir, model_type))]\n",
        "    preds  = []\n",
        "\n",
        "    for m in models:\n",
        "        model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)\n",
        "        model.load_state_dict(torch.load(m))\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            g, x = g_test, x_test\n",
        "            g = g.permute((0, 3, 1, 2))\n",
        "            pred = model(g, x).detach().cpu().numpy()\n",
        "        preds.append(pred)\n",
        "\n",
        "    # AVERAGE PREDICTIONS\n",
        "    preds = np.squeeze(np.array(preds))\n",
        "    preds = np.mean(preds, axis=0)\n",
        "    preds = np.exp(preds) - 1\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def pe_score(Ref_seq: str,\n",
        "            ED_seq: str,\n",
        "            sAlt: str,\n",
        "            sID:str       = 'Sample',\n",
        "            pe_system:str = 'PE2max',\n",
        "            cell_type:str = 'HEK293T',\n",
        "            pbs_min:int   = 7,\n",
        "            pbs_max:int   = 15,\n",
        "            rtt_max:int   = 40\n",
        "            ):\n",
        "\n",
        "    nAltIndex   = 60\n",
        "    pbs_range   = [pbs_min, pbs_max]\n",
        "    rtt_max     = rtt_max\n",
        "    pe_system   = pe_system\n",
        "\n",
        "    edit_type   = sAlt[:-1].lower()\n",
        "    edit_len    = int(sAlt[-1])\n",
        "\n",
        "    # check input parameters\n",
        "    if pbs_max > 17: return print('sID:%s\\nPlease set PBS max length upto 17nt' % sID)\n",
        "    if rtt_max > 40: return print('sID:%s\\nPlease set RTT max length upto 40nt' % sID)\n",
        "    if edit_type not in ['sub', 'ins', 'del']: return print('sID:%s\\nPlease select proper edit type.\\nAvailable edit tyle: sub, ins, del' % sID)\n",
        "    if edit_len > 3: return print('sID:%s\\nPlease set edit length upto 3nt. Available edit length range: 1~3nt' % sID)\n",
        "    if edit_len < 1: return print('sID:%s\\nPlease set edit length at least 1nt. Available edit length range: 1~3nt' % sID)\n",
        "\n",
        "\n",
        "#FeatureExtraction Class\n",
        "# بتدا تمام رشته راهنما های ممکن ساخته می شود\n",
        "# تابعی را فراخوانی می کنیم تا تمام ویژگی های مربوط به دنباله ها استخراج شود\n",
        "# سپس اطلاعات مربوط به ساختار دوم\n",
        "#در نهایت اطلاعات مربوط به اینتراکشن ژن ها\n",
        "#تابع مربوط به استخراج اطلاعات مربوط به اینتراکشن ژن ها را دارم ولی هنوز نمی دانم چه اطلاعاتی در اسکور دهی پرایم ادیتینگ تاثیر گذار هستند تا آن را به مدل اضافه کنم.\n",
        "\n",
        "    cFeat = FeatureExtraction()\n",
        "    cFeat.input_id = sID\n",
        "    cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n",
        "\n",
        "    cFeat.get_sAltNotation(nAltIndex)\n",
        "    cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)\n",
        "    cFeat.make_rt_pbs_combinations()\n",
        "    cFeat.determine_seqs()\n",
        "    cFeat.determine_secondary_structure()\n",
        "\n",
        "    df = cFeat.make_output_df()\n",
        "\n",
        "    if len(df) > 0:\n",
        "        list_Guide30 = [WT74[:30] for WT74 in df['WT74_On']]\n",
        "        df['DeepSpCas9_score'] = spcas9_score(list_Guide30)\n",
        "        df['%s_score' % pe_system]  = calculate_deepprime_score(df, pe_system, cell_type)\n",
        "\n",
        "    else:\n",
        "        print('\\nsID:', sID)\n",
        "        print('DeepPrime only support RTT length upto 40nt')\n",
        "        print('There are no available pegRNAs, please check your input sequences\\n')\n",
        "\n",
        "    return df\n",
        "\n",
        "def pecv_score(cv_record,\n",
        "               sID:str       = 'Sample',\n",
        "               pe_system:str = 'PE2max',\n",
        "               cell_type:str = 'HEK293T',\n",
        "               pbs_min:int   = 7,\n",
        "               pbs_max:int   = 15,\n",
        "               rtt_max:int   = 40\n",
        "               ):\n",
        "\n",
        "    '''\n",
        "    Using variants records from GetClinVar in the database module.\\n\n",
        "    You don't have to bring a sequence input to DeepPrime, but you calculate the score right away.\\n\n",
        "    If DeepPrime is an unpredictable form of variants, it sends out a message.\\n\n",
        "\n",
        "    '''\n",
        "\n",
        "    # check input parameters\n",
        "    if pbs_max > 17: return print('sID:%s\\nPlease set PBS max length upto 17nt' % sID)\n",
        "    if rtt_max > 40: return print('sID:%s\\nPlease set RTT max length upto 40nt' % sID)\n",
        "\n",
        "    print('DeepPrime score of ClinVar record')\n",
        "\n",
        "    Ref_seq, ED_seq = cv_record.seq()\n",
        "\n",
        "    nAltIndex   = 60\n",
        "    pbs_range   = [pbs_min, pbs_max]\n",
        "    rtt_max     = rtt_max\n",
        "    pe_system   = pe_system\n",
        "\n",
        "    edit_type   = cv_record.alt_type\n",
        "    edit_len    = int(cv_record.alt_len)\n",
        "\n",
        "    ## FeatureExtraction Class\n",
        "    cFeat = FeatureExtraction()\n",
        "\n",
        "    cFeat.input_id = sID\n",
        "    cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n",
        "\n",
        "    cFeat.get_sAltNotation(nAltIndex)\n",
        "    cFeat.get_all_RT_PBS(nAltIndex, nMinPBS=pbs_range[0]-1, nMaxPBS=pbs_range[1], nMaxRT=rtt_max, pe_system=pe_system)\n",
        "    cFeat.make_rt_pbs_combinations()\n",
        "    cFeat.determine_seqs()\n",
        "    cFeat.determine_secondary_structure()\n",
        "\n",
        "    df = cFeat.make_output_df()\n",
        "\n",
        "    if len(df) > 0:\n",
        "        list_Guide30 = [WT74[:30] for WT74 in df['WT74_On']]\n",
        "        df['DeepSpCas9_score'] = spcas9_score(list_Guide30)\n",
        "        df['%s_score' % pe_system]  = calculate_deepprime_score(df, pe_system, cell_type)\n",
        "\n",
        "    else:\n",
        "        print('\\nsID:', sID)\n",
        "        print('DeepPrime only support RTT length upto 40nt')\n",
        "        print('There are no available pegRNAs, please check your input sequences\\n')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#کد های کلاس زیر برای کنترل ورودی ها از سایت نوشته شده است.\n",
        "\n",
        "\n",
        "class DeepPrime:\n",
        "    '''\n",
        "    DeepPrime: pegRNA activity prediction models\\n\n",
        "    Input  = 121 nt DNA sequence without edit\\n\n",
        "    Output = 121 nt DNA sequence with edit\\n\n",
        "\n",
        "    ### Available Edit types\\n\n",
        "    sub1, sub2, sub3, ins1, ins2, ins3, del1, del2, del3\\n\n",
        "\n",
        "    ### Available PE systems\\n\n",
        "    PE2, PE2max, PE4max, NRCH_PE2, NRCH_PE2max, NRCH_PE4max\\n\n",
        "\n",
        "    ### Available Cell types\\n\n",
        "    HEK293T, HCT116, MDA-MB-231, HeLa, DLD1, A549, NIH3T3\n",
        "\n",
        "    '''\n",
        "    def __init__(self, sID:str, Ref_seq: str, ED_seq: str, edit_type: str, edit_len: int,\n",
        "                pam:str = 'NGG', pbs_min:int = 7, pbs_max:int = 15,\n",
        "                rtt_min:int = 0, rtt_max:int = 40, silence:bool = False,\n",
        "                out_dir:str=os.getcwd(),\n",
        "                ):\n",
        "\n",
        "        # input parameters\n",
        "        self.nAltIndex = 60\n",
        "        self.sID, self.Ref_seq, self.ED_seq = sID, Ref_seq, ED_seq\n",
        "        self.edit_type, self.edit_len, self.pam = edit_type, edit_len, pam\n",
        "        self.pbs_min, self.pbs_max = pbs_min, pbs_max\n",
        "        self.pbs_range = [pbs_min, pbs_max]\n",
        "        self.rtt_min, self.rtt_max   = rtt_min, rtt_max\n",
        "        self.silence = silence\n",
        "\n",
        "        # output directory\n",
        "        self.OUT_PATH = '%s/%s/'  % (out_dir, self.sID)\n",
        "        self.TEMP_DIR = '%s/temp' % self.OUT_PATH\n",
        "\n",
        "        # initializing\n",
        "        self.set_logging()\n",
        "        self.check_input()\n",
        "\n",
        "        ## FeatureExtraction Class\n",
        "        cFeat = FeatureExtraction()\n",
        "\n",
        "        cFeat.input_id = sID\n",
        "        cFeat.get_input(Ref_seq, ED_seq, edit_type, edit_len)\n",
        "\n",
        "        cFeat.get_sAltNotation(self.nAltIndex)\n",
        "        cFeat.get_all_RT_PBS(self.nAltIndex, nMinPBS= self.pbs_min-1, nMaxPBS=self.pbs_max, nMaxRT=rtt_max, pam=self.pam)\n",
        "        cFeat.make_rt_pbs_combinations()\n",
        "        cFeat.determine_seqs()\n",
        "        cFeat.determine_secondary_structure()\n",
        "\n",
        "        self.features = cFeat.make_output_df()\n",
        "\n",
        "        del cFeat\n",
        "\n",
        "        self.logger.info('Created an instance of DeepPrime')\n",
        "\n",
        "    # def __init__: END\n",
        "\n",
        "\n",
        "    def submit(self, pe_system:str, cell_type:str = 'HEK293T'):\n",
        "        print('start pe_scre', self.Ref_seq, self.ED_seq, )\n",
        "\n",
        "        return None\n",
        "\n",
        "    # def submit: END\n",
        "\n",
        "\n",
        "    def set_logging(self):\n",
        "\n",
        "        self.logger = logging.getLogger(self.OUT_PATH)\n",
        "        self.logger.setLevel(logging.DEBUG)\n",
        "\n",
        "        self.formatter = logging.Formatter(\n",
        "            '%(levelname)-5s @ %(asctime)s:\\n\\t %(message)s \\n',\n",
        "            datefmt='%a, %d %b %Y %H:%M:%S',\n",
        "            )\n",
        "\n",
        "        self.error = self.logger.error\n",
        "        self.warn  = self.logger.warn\n",
        "        self.debug = self.logger.debug\n",
        "        self.info  = self.logger.info\n",
        "\n",
        "        try:\n",
        "            os.makedirs(self.OUT_PATH, exist_ok=True)\n",
        "            os.makedirs(self.TEMP_DIR, exist_ok=True)\n",
        "            self.info('Creating Folder %s' % self.OUT_PATH)\n",
        "        except:\n",
        "            self.error('Creating Folder failed')\n",
        "            sys.exit(1)\n",
        "\n",
        "        self.file_handler = logging.FileHandler('%s/log_%s.log' % (self.OUT_PATH, self.sID))\n",
        "        self.file_handler.setLevel(logging.DEBUG)\n",
        "        self.file_handler.setFormatter(self.formatter)\n",
        "        self.logger.addHandler(self.file_handler)\n",
        "\n",
        "        if self.silence != True:\n",
        "            self.console_handler = logging.StreamHandler()\n",
        "            self.console_handler.setLevel(logging.DEBUG)\n",
        "            self.console_handler.setFormatter(self.formatter)\n",
        "            self.logger.addHandler(self.console_handler)\n",
        "\n",
        "        self.info('DeepPrime: pegRNA activity prediction models\\n\\t version: %s' % genet.__version__)\n",
        "\n",
        "\n",
        "        return None\n",
        "\n",
        "    # def set_logging: END\n",
        "\n",
        "\n",
        "    def check_input(self):\n",
        "\n",
        "        if self.pbs_min < 1:\n",
        "            self.error('sID:%s\\nPlease set PBS max length at least 1nt' % self.sID)\n",
        "            raise ValueError('Please check your input: pbs_min')\n",
        "\n",
        "        if self.pbs_max > 17:\n",
        "            self.error('sID:%s\\nPlease set PBS max length upto 17nt' % self.sID)\n",
        "            raise ValueError('Please check your input: pbs_max')\n",
        "\n",
        "        if self.rtt_max > 40:\n",
        "            self.error('sID:%s\\nPlease set RTT max length upto 40nt' % self.sID)\n",
        "            raise ValueError('Please check your input: rtt_max')\n",
        "\n",
        "        if self.edit_type not in ['sub', 'ins', 'del']:\n",
        "            self.error('sID:%s\\n\\t Please select proper edit type.\\n\\t Available edit tyle: sub, ins, del' % self.sID)\n",
        "            raise ValueError('Please check your input: edit_type')\n",
        "\n",
        "        if self.edit_len > 3:\n",
        "            self.error('sID:%s\\n\\t Please set edit length upto 3nt. Available edit length range: 1~3nt' % self.sID)\n",
        "            raise ValueError('Please check your input: edit_len')\n",
        "\n",
        "        if self.edit_len < 1:\n",
        "            self.error('sID:%s\\n\\t Please set edit length at least 1nt. Available edit length range: 1~3nt' % self.sID)\n",
        "            raise ValueError('Please check your input: edit_len')\n",
        "\n",
        "        self.info('Input information\\n\\t ID: %s\\n\\t Refseq: %s\\n\\t EDseq :%s' % (self.sID, self.Ref_seq, self.ED_seq))\n",
        "\n",
        "        return None\n",
        "\n",
        "    # def check_input: END\n",
        "\n",
        "\n",
        "    def do_something(self):\n",
        "        self.logger.info('Something happened.')\n",
        "\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Ew80A06LSOon"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#  WT sequence and Edited sequence information,  select the edit type you want to make and put it in.\n",
        "#Input seq: 60bp 5' context + 1bp center + 60bp 3' context (total 121bp)\n",
        "\n",
        "seq_wt   = 'ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGAAGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT'\n",
        "seq_ed   = 'ATGACAATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGAAACTGAGACGAACTATAACCTGCAAATGTCAACTGAAACCTTAAAGTGAGTATTTAATTGAGCTGAAGT'\n",
        "alt_type = 'sub3'\n",
        "\n",
        "df_pe = prd.pe_score(seq_wt, seq_ed, alt_type)\n",
        "df_pe.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "trQb7FNz8S2w",
        "outputId": "056f4cb8-eb1b-48ca-a2ca-fa7d9d8fc6f5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get model: DeepSpCas9\n",
            "get model: PE2max - HEK293T\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID                                            WT74_On  \\\n",
              "0  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "1  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "2  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "3  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "4  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "5  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "6  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "7  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "8  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "9  Sample  ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...   \n",
              "\n",
              "                                         Edited74_On  PBSlen  RTlen  \\\n",
              "0  xxxxxxxxxxxxxxCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...       7     37   \n",
              "1  xxxxxxxxxxxxxCCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...       8     37   \n",
              "2  xxxxxxxxxxxxACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...       9     37   \n",
              "3  xxxxxxxxxxxCACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...      10     37   \n",
              "4  xxxxxxxxxxACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...      11     37   \n",
              "5  xxxxxxxxxAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...      12     37   \n",
              "6  xxxxxxxxCAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...      13     37   \n",
              "7  xxxxxxxACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...      14     37   \n",
              "8  xxxxxxGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...      15     37   \n",
              "9  xxxxxxxxxxxxxxCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...       7     38   \n",
              "\n",
              "   RT-PBSlen  Edit_pos  Edit_len  RHA_len  type_sub  ...  nGCcnt1  nGCcnt2  \\\n",
              "0         44        34         3        1         1  ...        5       16   \n",
              "1         45        34         3        1         1  ...        6       16   \n",
              "2         46        34         3        1         1  ...        6       16   \n",
              "3         47        34         3        1         1  ...        7       16   \n",
              "4         48        34         3        1         1  ...        7       16   \n",
              "5         49        34         3        1         1  ...        7       16   \n",
              "6         50        34         3        1         1  ...        8       16   \n",
              "7         51        34         3        1         1  ...        8       16   \n",
              "8         52        34         3        1         1  ...        9       16   \n",
              "9         45        34         3        2         1  ...        5       17   \n",
              "\n",
              "   nGCcnt3   fGCcont1   fGCcont2   fGCcont3  MFE3  MFE4  DeepSpCas9_score  \\\n",
              "0       21  71.428571  43.243243  47.727273 -10.4  -0.6         45.967541   \n",
              "1       22  75.000000  43.243243  48.888889 -10.4  -0.6         45.967541   \n",
              "2       22  66.666667  43.243243  47.826087 -10.4  -0.6         45.967541   \n",
              "3       23  70.000000  43.243243  48.936170 -10.4  -0.6         45.967541   \n",
              "4       23  63.636364  43.243243  47.916667 -10.4  -0.6         45.967541   \n",
              "5       23  58.333333  43.243243  46.938776 -10.4  -0.6         45.967541   \n",
              "6       24  61.538462  43.243243  48.000000 -10.4  -0.6         45.967541   \n",
              "7       24  57.142857  43.243243  47.058824 -10.4  -0.6         45.967541   \n",
              "8       25  60.000000  43.243243  48.076923 -10.8  -0.6         45.967541   \n",
              "9       22  71.428571  44.736842  48.888889 -10.4  -0.6         45.967541   \n",
              "\n",
              "   PE2max_score  \n",
              "0      0.183205  \n",
              "1      0.567812  \n",
              "2      0.555785  \n",
              "3      0.880448  \n",
              "4      0.843616  \n",
              "5      0.726335  \n",
              "6      0.878919  \n",
              "7      0.807084  \n",
              "8      0.650619  \n",
              "9      0.320586  \n",
              "\n",
              "[10 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-80b3049f-1152-40d0-8e84-8466c7fcd286\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>WT74_On</th>\n",
              "      <th>Edited74_On</th>\n",
              "      <th>PBSlen</th>\n",
              "      <th>RTlen</th>\n",
              "      <th>RT-PBSlen</th>\n",
              "      <th>Edit_pos</th>\n",
              "      <th>Edit_len</th>\n",
              "      <th>RHA_len</th>\n",
              "      <th>type_sub</th>\n",
              "      <th>...</th>\n",
              "      <th>nGCcnt1</th>\n",
              "      <th>nGCcnt2</th>\n",
              "      <th>nGCcnt3</th>\n",
              "      <th>fGCcont1</th>\n",
              "      <th>fGCcont2</th>\n",
              "      <th>fGCcont3</th>\n",
              "      <th>MFE3</th>\n",
              "      <th>MFE4</th>\n",
              "      <th>DeepSpCas9_score</th>\n",
              "      <th>PE2max_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxxxxxxCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>7</td>\n",
              "      <td>37</td>\n",
              "      <td>44</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>47.727273</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.183205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxxxxxCCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>45</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>48.888889</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.567812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxxxxACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>9</td>\n",
              "      <td>37</td>\n",
              "      <td>46</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>47.826087</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.555785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxxxCACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>10</td>\n",
              "      <td>37</td>\n",
              "      <td>47</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>48.936170</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.880448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxxACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>11</td>\n",
              "      <td>37</td>\n",
              "      <td>48</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>63.636364</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>47.916667</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.843616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>12</td>\n",
              "      <td>37</td>\n",
              "      <td>49</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>58.333333</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>46.938776</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.726335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxCAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>13</td>\n",
              "      <td>37</td>\n",
              "      <td>50</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.878919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>14</td>\n",
              "      <td>37</td>\n",
              "      <td>51</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>57.142857</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>47.058824</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.807084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>15</td>\n",
              "      <td>37</td>\n",
              "      <td>52</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>25</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>43.243243</td>\n",
              "      <td>48.076923</td>\n",
              "      <td>-10.8</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.650619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sample</td>\n",
              "      <td>ATAAAAGACAACACCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>xxxxxxxxxxxxxxCCTTGCCTTGTGGAGTTTTCAAAGCTCCCAGA...</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>45</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>71.428571</td>\n",
              "      <td>44.736842</td>\n",
              "      <td>48.888889</td>\n",
              "      <td>-10.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>45.967541</td>\n",
              "      <td>0.320586</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80b3049f-1152-40d0-8e84-8466c7fcd286')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-d1a70d3d-49bf-43b4-bfe9-f2b51729092b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1a70d3d-49bf-43b4-bfe9-f2b51729092b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-d1a70d3d-49bf-43b4-bfe9-f2b51729092b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80b3049f-1152-40d0-8e84-8466c7fcd286 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80b3049f-1152-40d0-8e84-8466c7fcd286');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}